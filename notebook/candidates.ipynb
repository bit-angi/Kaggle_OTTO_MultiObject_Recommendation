{
 "cells": [
  {
   "cell_type": "code",
   "id": "eb50e59f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T08:52:49.488129Z",
     "start_time": "2025-09-24T08:52:39.875558Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_df = pd.read_parquet('../data/train.parquet')\n",
    "test_df = pd.read_parquet('../data/CV/valid_seqs.parquet')\n",
    "seven_days = 7*24*60*60\n",
    "train_cutoff = train_df.ts.max() - seven_days\n",
    "train_df = train_df[train_df.ts <= train_cutoff]\n",
    "test_df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          session      aid          ts  type\n",
       "0        11098528    11830  1661119200     0\n",
       "1        11098528  1679529  1661119417     0\n",
       "2        11098528    92401  1661119474     0\n",
       "3        11098528  1055218  1661119598     0\n",
       "4        11098528  1561739  1661119644     0\n",
       "...           ...      ...         ...   ...\n",
       "7686120  12899774    33035  1661723968     0\n",
       "7686121  12899775  1743151  1661723970     0\n",
       "7686122  12899776   548599  1661723972     0\n",
       "7686123  12899777   384045  1661723976     0\n",
       "7686124  12899778   561560  1661723983     0\n",
       "\n",
       "[7686125 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "      <th>ts</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098528</td>\n",
       "      <td>11830</td>\n",
       "      <td>1661119200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11098528</td>\n",
       "      <td>1679529</td>\n",
       "      <td>1661119417</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11098528</td>\n",
       "      <td>92401</td>\n",
       "      <td>1661119474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11098528</td>\n",
       "      <td>1055218</td>\n",
       "      <td>1661119598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11098528</td>\n",
       "      <td>1561739</td>\n",
       "      <td>1661119644</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7686120</th>\n",
       "      <td>12899774</td>\n",
       "      <td>33035</td>\n",
       "      <td>1661723968</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7686121</th>\n",
       "      <td>12899775</td>\n",
       "      <td>1743151</td>\n",
       "      <td>1661723970</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7686122</th>\n",
       "      <td>12899776</td>\n",
       "      <td>548599</td>\n",
       "      <td>1661723972</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7686123</th>\n",
       "      <td>12899777</td>\n",
       "      <td>384045</td>\n",
       "      <td>1661723976</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7686124</th>\n",
       "      <td>12899778</td>\n",
       "      <td>561560</td>\n",
       "      <td>1661723983</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7686125 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T08:53:00.234664Z",
     "start_time": "2025-09-24T08:53:00.072667Z"
    }
   },
   "cell_type": "code",
   "source": "train_df.session.max()",
   "id": "cc7030c032cac6a6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11098527"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "903c98a9e4c2ec02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T09:02:41.862733Z",
     "start_time": "2025-09-24T08:53:01.240975Z"
    }
   },
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "DO_LOCAL_VALIDATION = True\n",
    "if DO_LOCAL_VALIDATION:\n",
    "    seven_days = 7*24*60*60\n",
    "    train_cutoff = train_df.ts.max() - seven_days\n",
    "    test_df = train_df[train_df.ts > train_cutoff]\n",
    "    train_df = train_df[train_df.ts <= train_cutoff]\n",
    "\n",
    "    # 丢弃跨越train test的session\n",
    "    overlapped_session = set(train_df.session).intersection(test_df.session)\n",
    "    test_df = test_df[~test_df.session.isin(overlapped_session)]\n",
    "\n",
    "    new_test = []\n",
    "    data_to_cal_validation_score = []\n",
    "    for grp in tqdm(test_df.groupby(\"session\")):\n",
    "        if grp[1].shape[0] < 2 : continue\n",
    "        cutoff = np.random.randint(1,grp[1].shape[0])\n",
    "        new_test.append(grp[1].iloc[:cutoff])\n",
    "        data_to_cal_validation_score.append(grp[1].iloc[cutoff:])\n",
    "    test_df = pd.concat(new_test).reset_index(drop=True)\n",
    "    valid = pd.concat(data_to_cal_validation_score).reset_index(drop=True)\n",
    "\n",
    "    test_df.to_parquet('../data/CV/local_train2.parquet')\n",
    "    valid.to_parquet('../data/CV/local_train2_labels.parquet')\n",
    "    train_df.to_parquet(\"../data/CV/local_train1.parquet\")\n",
    "    del new_test, data_to_cal_validation_score\n",
    "else :\n",
    "    seven_days = 7*24*60*60\n",
    "    train_cutoff = train_df.ts.max() - seven_days\n",
    "    train_df = train_df[train_df.ts <= train_cutoff]"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2455308/2455308 [03:46<00:00, 10820.49it/s]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "581d5d8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T09:03:33.345450Z",
     "start_time": "2025-09-24T09:03:33.338386Z"
    }
   },
   "source": [
    "fraction_of_sessions_to_use = 1\n",
    "if fraction_of_sessions_to_use != 1 :\n",
    "    lucky_sessions_train = train_df.drop_duplicates(['session']).sample(frac=fraction_of_sessions_to_use,random_state=42)['session']\n",
    "    subset_of_train = train_df[train_df.session.isin(lucky_sessions_train)]\n",
    "    lucky_sessions_test = test_df.drop_duplicates(['session'])['session']\n",
    "    subset_of_test = test_df[test_df.session.isin(lucky_sessions_test)]\n",
    "else :\n",
    "    subset_of_train = train_df\n",
    "    subset_of_test = test_df\n",
    "\n",
    "subset_of_train.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   session      aid          ts  type\n",
       "0        0  1517085  1659304800     0\n",
       "1        0  1563459  1659304904     0\n",
       "2        0  1309446  1659367439     0\n",
       "3        0    16246  1659367719     0\n",
       "4        0  1781822  1659367871     0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "      <th>ts</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1517085</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1563459</td>\n",
       "      <td>1659304904</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1309446</td>\n",
       "      <td>1659367439</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>16246</td>\n",
       "      <td>1659367719</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1781822</td>\n",
       "      <td>1659367871</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T09:06:38.213225Z",
     "start_time": "2025-09-24T09:06:38.102540Z"
    }
   },
   "cell_type": "code",
   "source": "subset_of_train.session.max()",
   "id": "819fb5f4ab757ba9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8643219"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T09:06:47.869979Z",
     "start_time": "2025-09-24T09:06:47.854958Z"
    }
   },
   "cell_type": "code",
   "source": "subset_of_test.session.max()",
   "id": "392e721f81f078ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11098509"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "b8d9a7db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T09:07:18.617164Z",
     "start_time": "2025-09-24T09:07:18.606910Z"
    }
   },
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict,Counter\n",
    "\n",
    "def recall_covisitation_matrix(train,test,recall_num):\n",
    "    subset_of_train = train\n",
    "    subset_of_test = test\n",
    "    subset_of_train.index = pd.MultiIndex.from_frame(subset_of_train[['session']])\n",
    "    subset_of_test.index = pd.MultiIndex.from_frame(subset_of_test[['session']])\n",
    "    chunk_size = 3000000\n",
    "    min_ts = subset_of_train.ts.min()\n",
    "    max_ts = subset_of_train.ts.max()\n",
    "\n",
    "    next_AIDs = defaultdict(Counter)\n",
    "    # subsets = pd.concat([subset_of_train, subset_of_test])\n",
    "    subsets = subset_of_train\n",
    "    sessions = subsets.session.unique()\n",
    "\n",
    "    for i in tqdm(range(0,sessions.shape[0],chunk_size)):\n",
    "        current_chunk = subsets.loc[sessions[i]:sessions[min(sessions.shape[0]-1,i+chunk_size-1)]].reset_index(drop=True)\n",
    "        current_chunk = current_chunk.groupby('session',as_index=False).nth(list(range(-30,0))).reset_index(drop=True)\n",
    "        consecutive_AIDs = current_chunk.merge(current_chunk,on='session')\n",
    "        consecutive_AIDs = consecutive_AIDs[consecutive_AIDs['aid_x'] != consecutive_AIDs['aid_y']]\n",
    "        consecutive_AIDs['days_elapsed'] = (consecutive_AIDs.ts_y - consecutive_AIDs.ts_x) / (24*60*60)\n",
    "        consecutive_AIDs = consecutive_AIDs[(consecutive_AIDs.days_elapsed >= 0) & (consecutive_AIDs.days_elapsed <= 1)]\n",
    "        for aid_x , aid_y in zip(consecutive_AIDs['aid_x'], consecutive_AIDs['aid_y']):\n",
    "            next_AIDs[aid_x][aid_y] += 1\n",
    "\n",
    "    session_type = ['clicks','carts','orders']\n",
    "    test_session_AIDs = test_df.reset_index(drop=True).groupby('session')['aid'].apply(list)\n",
    "    test_session_types = test_df.reset_index(drop=True).groupby('session')['type'].apply(list)\n",
    "    labels = []\n",
    "    no_data = 0\n",
    "    no_data_all_aids = 0\n",
    "    type_weight_multipliers = {0:1,1:6,2:3}\n",
    "    for AIDs , types in tqdm(zip(test_session_AIDs,test_session_types),total=len(test_session_types)):\n",
    "        if len(AIDs) >= 30 :\n",
    "            weights = np.logspace(0.1,1,len(AIDs),base=2,endpoint=True)\n",
    "            aids_temp = defaultdict(lambda : 0)\n",
    "            for aid,w,t in zip(AIDs,weights,types):\n",
    "                aids_temp[aid] += w * type_weight_multipliers[t]\n",
    "            sorted_aids = [k for k,v in sorted(aids_temp.items(),key=lambda item:-item[1])]\n",
    "            labels.append(sorted_aids[:recall_num])\n",
    "        else :\n",
    "            AIDs = list(dict.fromkeys(AIDs[::-1]))\n",
    "            AIDs_len_start = len(AIDs)\n",
    "\n",
    "            candidates = []\n",
    "            for AID in AIDs:\n",
    "                if AID in next_AIDs: candidates += [aid for aid, count in next_AIDs[AID].most_common(20)]\n",
    "            AIDs += [AID for AID, cnt in Counter(candidates).most_common(recall_num) if AID not in AIDs]\n",
    "\n",
    "            labels.append(AIDs[:recall_num])\n",
    "            if candidates == []: no_data += 1\n",
    "            if AIDs_len_start == len(AIDs): no_data_all_aids += 1\n",
    "    return pd.DataFrame(data={'session_type': test_session_AIDs.index, 'labels': labels})\n"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "5d33409a",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-09-24T09:07:27.674786Z"
    }
   },
   "source": [
    "recall1 = recall_covisitation_matrix(subset_of_train,subset_of_test,recall_num=150)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45b9fe994dea7614",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T09:48:47.244365Z",
     "start_time": "2025-09-23T09:48:45.639405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "      <th>ts</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1517085</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1563459</td>\n",
       "      <td>1659304904</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1309446</td>\n",
       "      <td>1659367439</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>16246</td>\n",
       "      <td>1659367719</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1781822</td>\n",
       "      <td>1659367871</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163955176</th>\n",
       "      <td>11098523</td>\n",
       "      <td>175715</td>\n",
       "      <td>1661119197</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163955177</th>\n",
       "      <td>11098524</td>\n",
       "      <td>1088524</td>\n",
       "      <td>1661119198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163955178</th>\n",
       "      <td>11098525</td>\n",
       "      <td>182927</td>\n",
       "      <td>1661119199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163955179</th>\n",
       "      <td>11098526</td>\n",
       "      <td>510055</td>\n",
       "      <td>1661119199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163955180</th>\n",
       "      <td>11098527</td>\n",
       "      <td>1659014</td>\n",
       "      <td>1661119199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163955181 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            session      aid          ts  type\n",
       "0                 0  1517085  1659304800     0\n",
       "1                 0  1563459  1659304904     0\n",
       "2                 0  1309446  1659367439     0\n",
       "3                 0    16246  1659367719     0\n",
       "4                 0  1781822  1659367871     0\n",
       "...             ...      ...         ...   ...\n",
       "163955176  11098523   175715  1661119197     0\n",
       "163955177  11098524  1088524  1661119198     0\n",
       "163955178  11098525   182927  1661119199     0\n",
       "163955179  11098526   510055  1661119199     0\n",
       "163955180  11098527  1659014  1661119199     0\n",
       "\n",
       "[163955181 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b8260e65e3cc064",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T10:31:54.899134Z",
     "start_time": "2025-09-23T09:48:47.719656Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# 训练 Word2Vec\n",
    "recall_num=20\n",
    "vector_size=64\n",
    "window=5\n",
    "sg=1\n",
    "min_count=1\n",
    "workers=4\n",
    "sessions = train_df.groupby(\"session\")['aid'].apply(list).tolist()\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=[[str(a) for a in s] for s in sessions],\n",
    "    vector_size=vector_size,\n",
    "    window=window,\n",
    "    sg=sg,\n",
    "    min_count=min_count,\n",
    "    workers=workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2ce85e175055285",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T10:31:55.481319Z",
     "start_time": "2025-09-23T10:31:55.330381Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import normalize\n",
    "from gensim.models import Word2Vec\n",
    "import faiss\n",
    "\n",
    "def recall_word2vec(train, test, recall_num=100, w2v_model=None):\n",
    "    \"\"\"\n",
    "    Word2Vec 批量 Faiss 召回 (避免循环每个 aid)\n",
    "    \"\"\"\n",
    "    # ===== 训练 Word2Vec 模型 =====\n",
    "    if w2v_model is None:\n",
    "        sessions = train.groupby(\"session\")['aid'].apply(list).tolist()\n",
    "        w2v_model = Word2Vec(\n",
    "            sentences=[[str(a) for a in s] for s in sessions],\n",
    "            vector_size=64, window=5, sg=1, min_count=1, workers=4\n",
    "        )\n",
    "\n",
    "    # ===== 构建 Faiss 索引 =====\n",
    "    keys = w2v_model.wv.index_to_key\n",
    "    emb_matrix = normalize(w2v_model.wv.vectors).astype('float32')\n",
    "    aid2idx = {int(k): i for i, k in enumerate(keys)}\n",
    "\n",
    "    d = emb_matrix.shape[1]\n",
    "    index = faiss.IndexFlatIP(d)\n",
    "    index.add(emb_matrix)\n",
    "\n",
    "    # ===== 测试集 =====\n",
    "    test = test.reset_index(drop=True)\n",
    "    test_grouped = test.groupby('session').agg(list)\n",
    "    test_session_AIDs = test_grouped['aid']\n",
    "    test_session_types = test_grouped['type']\n",
    "\n",
    "    labels = []\n",
    "    type_weight_multipliers = {0:1, 1:6, 2:3}\n",
    "\n",
    "    # --- 收集所有短 session 的 aid，一次性批量查询 ---\n",
    "    short_sessions = []\n",
    "    short_aids = set()\n",
    "    for idx, AIDs in tqdm(enumerate(test_session_AIDs)):\n",
    "        AIDs = list(dict.fromkeys(AIDs[::-1]))  # 最近交互优先\n",
    "        short_sessions.append((idx, AIDs))\n",
    "        short_aids.update([aid for aid in AIDs if aid in aid2idx])\n",
    "\n",
    "    short_aids = list(short_aids)\n",
    "    if short_aids:\n",
    "        query_vecs = np.array([normalize(w2v_model.wv[str(aid)].reshape(1, -1))[0] for aid in tqdm(short_aids)], dtype='float32')\n",
    "        D, I = index.search(query_vecs, 30)  # batch search\n",
    "        print(\"查询完成\")\n",
    "        # 构建 aid -> topn candidates 映射\n",
    "        aid2candidates = {aid: [int(keys[i]) for i in row if int(keys[i]) != aid][:30]\n",
    "                          for aid, row in tqdm(zip(short_aids, I), total=len(short_aids))}\n",
    "    else:\n",
    "        aid2candidates = {}\n",
    "\n",
    "    # --- 生成最终 labels ---\n",
    "    for idx, AIDs in tqdm(enumerate(test_session_AIDs)):\n",
    "        if len(AIDs) >= 30:\n",
    "            AIDs = AIDs[:30]\n",
    "\n",
    "        AIDs = list(dict.fromkeys(AIDs[::-1]))\n",
    "        candidates = []\n",
    "        for aid in AIDs:\n",
    "            if aid in aid2candidates:\n",
    "                candidates.extend(aid2candidates[aid])\n",
    "        # 去重补全\n",
    "        AIDs = []\n",
    "        AIDs += [AID for AID, cnt in Counter(candidates).most_common(recall_num) if AID not in AIDs]\n",
    "        labels.append(AIDs[:recall_num])\n",
    "\n",
    "    return pd.DataFrame({'session_type': test_session_AIDs.index, 'labels': labels})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f59b6ae7cbff7e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T10:40:06.022911Z",
     "start_time": "2025-09-23T10:31:55.493750Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1801251it [00:25, 71486.44it/s] \n",
      "100%|██████████| 856251/856251 [01:10<00:00, 12215.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查询完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 856251/856251 [00:12<00:00, 66693.84it/s]\n",
      "1801251it [01:08, 26446.05it/s]\n"
     ]
    }
   ],
   "source": [
    "recall2 = recall_word2vec(subset_of_train,subset_of_test,recall_num=100,w2v_model=w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21072f4bcb2dd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb5ab56bb078c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555edf1f51c31da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def merge_recalls_with_rank(*recalls, topk=None):\n",
    "    \"\"\"\n",
    "    合并多个召回 DataFrame，去重并保留每个 aid 在各个召回中的原始排名\n",
    "    参数:\n",
    "        *recalls: 任意数量的 DataFrame，每个包含 'session_type' 和 'labels'\n",
    "        topk: 合并后取前 topk 个 aid\n",
    "    返回:\n",
    "        merged_df: 合并去重后的 DataFrame，包含 'session_type' 和 'labels'\n",
    "        aid_rank_all: 每个 session 的 aid 在各个召回中的排名列表\n",
    "    \"\"\"\n",
    "    if not recalls:\n",
    "        return None, None\n",
    "\n",
    "    # 确保 merged_df 有 labels 列\n",
    "    merged_df = recalls[0][['session_type']].copy()\n",
    "    merged_df['labels'] = [[] for _ in range(len(merged_df))]\n",
    "\n",
    "    session_ids = merged_df['session_type'].tolist()\n",
    "    aid_rank_all = {}\n",
    "\n",
    "    # 遍历每个 session\n",
    "    for session in tqdm(session_ids):\n",
    "        combined = []\n",
    "        rank_dict = defaultdict(lambda: [None]*len(recalls))\n",
    "\n",
    "        for i, recall_df in enumerate(recalls):\n",
    "            row = recall_df[recall_df['session_type']==session]\n",
    "            if row.empty:\n",
    "                continue\n",
    "            labels = row['labels'].values[0]\n",
    "            for rank, aid in enumerate(labels):\n",
    "                if aid not in combined:\n",
    "                    combined.append(aid)\n",
    "                if rank_dict[aid][i] is None:\n",
    "                    rank_dict[aid][i] = rank\n",
    "\n",
    "        if topk:\n",
    "            combined = combined[:topk]\n",
    "\n",
    "        # 用 .at 安全赋值单元格，避免 loc 批量赋值报错\n",
    "        idx = merged_df[merged_df['session_type']==session].index[0]\n",
    "        merged_df.at[idx, 'labels'] = combined\n",
    "        aid_rank_all[session] = rank_dict\n",
    "\n",
    "    return merged_df, aid_rank_all\n",
    "\n",
    "# 使用示例\n",
    "recalled, rank_df = merge_recalls_with_rank(recall1, recall2, topk=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c47d297f7ad82a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a414390cce734e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalled.to_parquet(\"../output/recall.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd13244ecbeeb22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def rank_dict_to_df(aid_rank_all):\n",
    "    rows = []\n",
    "    for session, rank_dict in tqdm(aid_rank_all.items()):\n",
    "        for aid, ranks in rank_dict.items():\n",
    "            rows.append({\n",
    "                \"session_type\": session,\n",
    "                \"aid\": aid,\n",
    "                **{f\"recall{i+1}_rank\": r for i, r in enumerate(ranks)}\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# 转换并保存\n",
    "rank_df = rank_dict_to_df(rank_df)\n",
    "rank_df.to_parquet(\"aid_ranks.parquet\", index=False)  # 保存成 parquet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2656f2fa8478c5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2441f2597b8dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ae9f250bb8fea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d83ee2ba9662c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "curvalid = valid[valid.type == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf43142ed5db8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(recalled,curvalid,left_on=\"session_type\",right_on=\"session\",how=\"left\")\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be2e58f5b88231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.groupby(\"session_type\").head(1)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c8ca54e17d65f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db414995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall_at_k(pred_df, valid_df, k=20):\n",
    "    \"\"\"\n",
    "    严格按照比赛规则计算Recall@K\n",
    "    \n",
    "    参数:\n",
    "    - pred_df: 预测结果DataFrame，包含'session_type'和'labels'列\n",
    "    - valid_df: 验证集DataFrame，包含'session', 'aid', 'type'列\n",
    "    - k: topk的k值，默认20\n",
    "    \n",
    "    返回:\n",
    "    - 各类型的recall值和加权平均\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # 处理clicks: 只看下一个点击\n",
    "    clicks_valid = valid_df[valid_df.type == 0].copy()\n",
    "    clicks_valid = clicks_valid.sort_values(['session', 'ts'])\n",
    "    # 只取每个session第一个click\n",
    "    first_clicks = clicks_valid.groupby('session', as_index=False).first()\n",
    "    \n",
    "    if len(first_clicks) > 0:\n",
    "        hits = 0\n",
    "        for _, row in first_clicks.iterrows():\n",
    "            session = row['session']\n",
    "            next_click = row['aid']\n",
    "            pred_row = pred_df[pred_df['session_type'] == session]\n",
    "            if len(pred_row) > 0:\n",
    "                pred_aids = pred_row.iloc[0]['labels'][:k]\n",
    "                if next_click in pred_aids:\n",
    "                    hits += 1\n",
    "        clicks_recall = hits / len(first_clicks)\n",
    "        results['clicks'] = clicks_recall\n",
    "        print(f\"Clicks Recall@{k}: {clicks_recall:.4f} ({hits}/{len(first_clicks)})\")\n",
    "    \n",
    "    # 处理carts和orders\n",
    "    for type_id, type_name in [(1, 'carts'), (2, 'orders')]:\n",
    "        type_valid = valid_df[valid_df.type == type_id]\n",
    "        if len(type_valid) > 0:\n",
    "            recall_sum = 0\n",
    "            valid_sessions = 0\n",
    "            \n",
    "            # 按session分组获取真实的aid列表\n",
    "            for session, group in type_valid.groupby('session'):\n",
    "                pred_row = pred_df[pred_df['session_type'] == session]\n",
    "                if len(pred_row) > 0:\n",
    "                    pred_aids = pred_row.iloc[0]['labels'][:k]\n",
    "                    true_aids = set(group['aid'].unique())\n",
    "                    \n",
    "                    # 分母取真实aid数量和k的最小值\n",
    "                    denominator = min(len(true_aids), k)\n",
    "                    # 分子是预测集合与真实集合的交集大小\n",
    "                    hits = len(set(pred_aids).intersection(true_aids))\n",
    "                    \n",
    "                    recall_sum += hits / denominator\n",
    "                    valid_sessions += 1\n",
    "            \n",
    "            if valid_sessions > 0:\n",
    "                type_recall = recall_sum / valid_sessions\n",
    "                results[type_name] = type_recall\n",
    "                print(f\"{type_name.capitalize()} Recall@{k}: {type_recall:.4f} ({valid_sessions} sessions)\")\n",
    "    \n",
    "    # 计算加权平均\n",
    "    if len(results) == 3:  # 确保所有类型都有结果\n",
    "        weighted_recall = 0.1 * results['clicks'] + 0.3 * results['carts'] + 0.6 * results['orders']\n",
    "        results['weighted_avg'] = weighted_recall\n",
    "        print(f\"\\nWeighted Average Recall@{k}: {weighted_recall:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 计算召回率\n",
    "print(\"计算整体的召回率：\")\n",
    "metrics = calculate_recall_at_k(recalled, valid, k=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
